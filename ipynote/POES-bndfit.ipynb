{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import pandas\n",
    "import datetime\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minCutoffFitLat = 45.\n",
    "delTimeCutOffNrstSat = 45 # min\n",
    "mlonDiffOtrEndCutoff = 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file--> ../poes_n15_20130302_proc.nc\n",
      "reading file--> ../poes_n18_20130302_proc.nc\n",
      "reading file--> ../poes_m01_20130302_proc.nc\n",
      "reading file--> ../poes_n19_20130302_proc.nc\n",
      "reading file--> ../poes_m01_20130302_proc.nc\n",
      "reading file--> ../poes_n16_20130302_proc.nc\n",
      "reading file--> ../poes_n17_20130302_proc.nc\n"
     ]
    }
   ],
   "source": [
    "fileList = [ \"../poes_n15_20130302_proc.nc\",\\\n",
    "                \"../poes_n18_20130302_proc.nc\",\\\n",
    "                \"../poes_m01_20130302_proc.nc\",\\\n",
    "                \"../poes_n19_20130302_proc.nc\",\\\n",
    "                \"../poes_m01_20130302_proc.nc\",\\\n",
    "                \"../poes_n16_20130302_proc.nc\",\\\n",
    "                \"../poes_n17_20130302_proc.nc\" ]\n",
    "poesAllEleDataDF = pandas.DataFrame( columns =  [\"timestamp\", \"date\", \"aacgm_lat_foot\",\\\n",
    "                         \"aacgm_lon_foot\", \"MLT\", \"log_ele_flux\", \"sat\"] )\n",
    "poesAllProDataDF = pandas.DataFrame( columns =  [\"timestamp\", \"date\", \"aacgm_lat_foot\",\\\n",
    "                         \"aacgm_lon_foot\", \"MLT\", \"log_pro_flux\", \"sat\"] )\n",
    "for f in fileList:\n",
    "    print \"reading file-->\", f\n",
    "    # read variable from the netCDF files\n",
    "    poesRawData = netCDF4.Dataset(f)\n",
    "    poesDF = pandas.DataFrame( poesRawData.variables['time'][:], columns=[ \"timestamp\" ] )\n",
    "    poesDF['date'] = pandas.to_datetime(poesDF['timestamp'], unit='ms')\n",
    "    poesDF[\"alt\"] = poesRawData.variables['alt'][:]\n",
    "    poesDF[\"aacgm_lat_foot\"] = poesRawData.variables['aacgm_lat_foot'][:]\n",
    "\n",
    "    poesDF[\"aacgm_lon_foot\"] = poesRawData.variables['aacgm_lon_foot'][:]\n",
    "    poesDF[\"MLT\"] = poesRawData.variables['MLT'][:]\n",
    "    # round of to 2 decimals\n",
    "    poesDF['alt'] = [ round( x, 2 ) for x in poesDF['alt']]\n",
    "    poesDF['aacgm_lat_foot'] = [ round( x, 2 ) for x in poesDF['aacgm_lat_foot']]\n",
    "    poesDF['aacgm_lon_foot'] = [ round( x, 2 ) for x in poesDF['aacgm_lon_foot']]\n",
    "    poesDF['MLT'] = [ round( x, 2 ) for x in poesDF['MLT']]\n",
    "    # Add up the fluxes\n",
    "    poesDF[\"ted_ele_total_flux\"] = poesRawData.variables['ted_ele_tel0_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_ele_tel0_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel0_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel0_flux_14'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_14'][:]\n",
    "    poesDF[\"ted_pro_total_flux\"] = poesRawData.variables['ted_pro_tel0_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_pro_tel0_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel0_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel0_flux_14'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_14'][:]\n",
    "    poesDF['log_ele_flux'] = [0. if x <= 0. else round( numpy.log10(x), 2 )\\\n",
    "                 for x in poesDF['ted_ele_total_flux']]\n",
    "    poesDF['log_pro_flux'] = [0. if x <= 0. else round( numpy.log10(x), 2 )\\\n",
    "                 for x in poesDF['ted_pro_total_flux']]\n",
    "    # the current satellite number\n",
    "    poesDF[\"sat\"] = f[-19:-17]\n",
    "    # seperate out electron and proton flux and discard all zeros\n",
    "    currPoesEleFluxDF = poesDF[poesDF[\"log_ele_flux\"] > 0.][ [\"timestamp\",\\\n",
    "                     \"date\", \"aacgm_lat_foot\", \"aacgm_lon_foot\", \"MLT\",\\\n",
    "                     \"log_ele_flux\", \"sat\"] ].reset_index(drop=True)\n",
    "    currPoesProFluxDF = poesDF[poesDF[\"log_pro_flux\"] > 0.][ [\"timestamp\",\\\n",
    "                     \"date\", \"aacgm_lat_foot\", \"aacgm_lon_foot\", \"MLT\",\\\n",
    "                     \"log_pro_flux\", \"sat\"] ].reset_index(drop=True)\n",
    "    poesAllEleDataDF = poesAllEleDataDF.append( currPoesEleFluxDF )\n",
    "    poesAllProDataDF = poesAllProDataDF.append( currPoesProFluxDF )\n",
    "    # now delete all the rows for prev DFs\n",
    "    # we don't want to duplicate data\n",
    "    poesDF = poesDF.drop( poesDF.index )\n",
    "    currPoesEleFluxDF = currPoesEleFluxDF.drop( currPoesEleFluxDF.index )\n",
    "    currPoesProFluxDF = currPoesProFluxDF.drop( currPoesProFluxDF.index )\n",
    "# create a date and time columns\n",
    "poesAllEleDataDF[\"dateStr\"] = poesAllEleDataDF[\"date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "poesAllEleDataDF[\"time\"] = poesAllEleDataDF[\"date\"].map(lambda x: x.strftime('%H%M'))\n",
    "poesAllProDataDF[\"dateStr\"] = poesAllProDataDF[\"date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "poesAllProDataDF[\"time\"] = poesAllProDataDF[\"date\"].map(lambda x: x.strftime('%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-03-02 05:00:00.201000\n"
     ]
    }
   ],
   "source": [
    "timeRange = [ poesAllEleDataDF[\"date\"].min(), poesAllEleDataDF[\"date\"].max() ]\n",
    "ctime = timeRange[0]\n",
    "timeInterval=datetime.timedelta(minutes=30)\n",
    "while ctime <= timeRange[1]:\n",
    "    ctime += timeInterval\n",
    "    if abs( ctime - datetime.datetime(2013,3,2,5) ) < datetime.timedelta(minutes=1):\n",
    "        break\n",
    "print ctime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only need those times when POES was above minCutoffFitLat(45) MLAT\n",
    "poesAllEleDataDF = poesAllEleDataDF[ \\\n",
    "                ( abs( poesAllEleDataDF[\"aacgm_lat_foot\"] ) >= minCutoffFitLat )\\\n",
    "                ].reset_index(drop=True)\n",
    "# We only need a few columns, discard the rest\n",
    "poesAllEleDataDF = poesAllEleDataDF[ [ 'sat', 'date',\\\n",
    "                        'aacgm_lat_foot', 'aacgm_lon_foot',\\\n",
    "                            'MLT', 'log_ele_flux' ] ]\n",
    "poesAllEleDataDF[\"delCtime\"] = abs(poesAllEleDataDF[\"date\"] - ctime)\n",
    "poesAllEleDataDF[\"delLatFit\"] = abs( poesAllEleDataDF[\"aacgm_lat_foot\"] ) -\\\n",
    "                                    abs( minCutoffFitLat )\n",
    "# We are sorting by sats, dates and lats to pick the nearest time\n",
    "# when the satellite is between two 45 MLATs\n",
    "poesAllEleDataDFNth = poesAllEleDataDF[ poesAllEleDataDF[\"aacgm_lat_foot\"]\\\n",
    "                        >= 0. ].sort_values( ['sat', 'date', 'aacgm_lat_foot'],\\\n",
    "                                ascending=True ).reset_index(drop=True).drop_duplicates()\n",
    "poesAllEleDataDFSth = poesAllEleDataDF[ poesAllEleDataDF[\"aacgm_lat_foot\"]\\\n",
    "                        < 0. ].sort_values( ['sat', 'date', 'aacgm_lat_foot'],\\\n",
    "                                ascending=True ).reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sat</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2013-03-02 05:09:26.746</td>\n",
       "      <td>2013-03-02 05:36:16.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2013-03-02 04:55:20.987</td>\n",
       "      <td>2013-03-02 04:28:24.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>2013-03-02 04:21:50.193</td>\n",
       "      <td>2013-03-02 05:38:46.194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>2013-03-02 04:50:17.132</td>\n",
       "      <td>2013-03-02 03:31:43.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>2013-03-02 05:08:44.993</td>\n",
       "      <td>2013-03-02 04:42:54.993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sat              start_time                end_time\n",
       "0  01 2013-03-02 05:09:26.746 2013-03-02 05:36:16.744\n",
       "1  16 2013-03-02 04:55:20.987 2013-03-02 04:28:24.986\n",
       "2  17 2013-03-02 04:21:50.193 2013-03-02 05:38:46.194\n",
       "3  18 2013-03-02 04:50:17.132 2013-03-02 03:31:43.132\n",
       "4  19 2013-03-02 05:08:44.993 2013-03-02 04:42:54.993"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we need to pick the satellite path (between two 45 MLATs)\n",
    "# which is closest to the selected time.!\n",
    "currNthEleDF = poesAllEleDataDFNth[\\\n",
    "                    ( poesAllEleDataDFNth[\"delLatFit\"] <= 1. )\\\n",
    "                    ].sort_values( [\"sat\", \"delCtime\"], ascending=[True, True] )\n",
    "# Now if the time difference is too large, discard the satellite data\n",
    "dscrdSatList = currNthEleDF[ [\"sat\", \"delCtime\"] ].groupby( \"sat\" ).min()\n",
    "dscrdSatList = dscrdSatList[ \\\n",
    "                    dscrdSatList[\"delCtime\"] <= \\\n",
    "                    datetime.timedelta(minutes=delTimeCutOffNrstSat)\\\n",
    "                    ].reset_index()\n",
    "# only choose the satellites which are nearby\n",
    "currNthEleDF = currNthEleDF[ \\\n",
    "                currNthEleDF[\"sat\"].isin( \\\n",
    "                    dscrdSatList[\"sat\"].values ) ]\n",
    "# Now we need to identify the 45 to 45 MLAT path\n",
    "# Basically the satelllite should start at 45 MLAT\n",
    "# at one MLT/MLON and reach 45 MLAT at the other \n",
    "# extreme end ( different MLON )\n",
    "# Get the nearest 45 MLAT instance for each satellite,\n",
    "# substract its MLT with the rest and sort by date asc\n",
    "# and MLT desc!\n",
    "nrstSatInstance = currNthEleDF[ [\"sat\", \"delCtime\"]\\\n",
    "                    ].groupby( \"sat\" ).min().reset_index()\n",
    "# These are the starting times of 45-45 pass\n",
    "satSelTimes = nrstSatInstance[ [\"sat\", \"delCtime\"] ]\n",
    "satSelTimes.columns = [ [\"sat\", \"delCtime\"] ]\n",
    "satSelTimes = pandas.merge( satSelTimes, \\\n",
    "                currNthEleDF, on=[\"sat\", \"delCtime\"] )\n",
    "satSelTimes = satSelTimes[ [\"sat\", \"date\"] ]\n",
    "satSelTimes.columns = [ \"sat\", \"start_time\" ]\n",
    "nrstSatInstance =  pandas.merge( currNthEleDF, \\\n",
    "                        nrstSatInstance, \\\n",
    "                        on=[\"sat\", \"delCtime\"] )[ [\"sat\", \"aacgm_lon_foot\"] ]\n",
    "nrstSatInstance.columns = [ \"sat\", \"nrstTimeLon\" ]\n",
    "currNthEleDF = pandas.merge( currNthEleDF, nrstSatInstance, on=\"sat\" )\n",
    "currNthEleDF[\"delLon\"] = abs(currNthEleDF[\"aacgm_lon_foot\"] \\\n",
    "                            - currNthEleDF[\"nrstTimeLon\"]).astype(int)\n",
    "# Now when the satellite moves to other 45 MLAT\n",
    "# ( at the opposite end of the Earth). We'll set a\n",
    "# cutoff to discard the other values\n",
    "currNthEleDF = currNthEleDF[ currNthEleDF[\"delLon\"] \\\n",
    "                            > mlonDiffOtrEndCutoff \\\n",
    "                           ].reset_index(drop=True)\n",
    "\n",
    "currNthEleDF = currNthEleDF.sort_values( [\"sat\", \"delCtime\", \"delLon\"],\\\n",
    "                                ascending=[True, True, False] )\n",
    "# Now get the first row of each SAT group\n",
    "currNthEleDF = currNthEleDF.groupby(\"sat\").first().reset_index()\n",
    "satSelTimes = pandas.merge( satSelTimes, currNthEleDF[ [\"sat\", \"date\"] ],\\\n",
    "                         on=\"sat\")\n",
    "satSelTimes.columns = [ \"sat\", \"start_time\", \"end_time\" ]\n",
    "satSelTimes.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
