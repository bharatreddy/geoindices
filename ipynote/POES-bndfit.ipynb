{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import netCDF4\n",
    "import pandas\n",
    "import datetime\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minCutoffFitLat = 45.\n",
    "delTimeCutOffNrstPass = 45 # min\n",
    "mlonDiffOtrEndCutoff = 50.\n",
    "delLatCutoff = 2.\n",
    "delCtimeCutoff = 60. #min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file--> ../poes_n15_20130302_proc.nc\n",
      "reading file--> ../poes_n18_20130302_proc.nc\n",
      "reading file--> ../poes_m01_20130302_proc.nc\n",
      "reading file--> ../poes_n19_20130302_proc.nc\n",
      "reading file--> ../poes_m01_20130302_proc.nc\n",
      "reading file--> ../poes_n16_20130302_proc.nc\n",
      "reading file--> ../poes_n17_20130302_proc.nc\n"
     ]
    }
   ],
   "source": [
    "fileList = [ \"../poes_n15_20130302_proc.nc\",\\\n",
    "                \"../poes_n18_20130302_proc.nc\",\\\n",
    "                \"../poes_m01_20130302_proc.nc\",\\\n",
    "                \"../poes_n19_20130302_proc.nc\",\\\n",
    "                \"../poes_m01_20130302_proc.nc\",\\\n",
    "                \"../poes_n16_20130302_proc.nc\",\\\n",
    "                \"../poes_n17_20130302_proc.nc\" ]\n",
    "poesAllEleDataDF = pandas.DataFrame( columns =  [\"timestamp\", \"date\", \"aacgm_lat_foot\",\\\n",
    "                         \"aacgm_lon_foot\", \"MLT\", \"log_ele_flux\", \"sat\"] )\n",
    "poesAllProDataDF = pandas.DataFrame( columns =  [\"timestamp\", \"date\", \"aacgm_lat_foot\",\\\n",
    "                         \"aacgm_lon_foot\", \"MLT\", \"log_pro_flux\", \"sat\"] )\n",
    "for f in fileList:\n",
    "    print \"reading file-->\", f\n",
    "    # read variable from the netCDF files\n",
    "    poesRawData = netCDF4.Dataset(f)\n",
    "    poesDF = pandas.DataFrame( poesRawData.variables['time'][:], columns=[ \"timestamp\" ] )\n",
    "    poesDF['date'] = pandas.to_datetime(poesDF['timestamp'], unit='ms')\n",
    "    poesDF[\"alt\"] = poesRawData.variables['alt'][:]\n",
    "    poesDF[\"aacgm_lat_foot\"] = poesRawData.variables['aacgm_lat_foot'][:]\n",
    "\n",
    "    poesDF[\"aacgm_lon_foot\"] = poesRawData.variables['aacgm_lon_foot'][:]\n",
    "    poesDF[\"MLT\"] = poesRawData.variables['MLT'][:]\n",
    "    # round of to 2 decimals\n",
    "    poesDF['alt'] = [ round( x, 2 ) for x in poesDF['alt']]\n",
    "    poesDF['aacgm_lat_foot'] = [ round( x, 2 ) for x in poesDF['aacgm_lat_foot']]\n",
    "    poesDF['aacgm_lon_foot'] = [ round( x, 2 ) for x in poesDF['aacgm_lon_foot']]\n",
    "    poesDF['MLT'] = [ round( x, 2 ) for x in poesDF['MLT']]\n",
    "    # Add up the fluxes\n",
    "    poesDF[\"ted_ele_total_flux\"] = poesRawData.variables['ted_ele_tel0_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_ele_tel0_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel0_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel0_flux_14'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_ele_tel30_flux_14'][:]\n",
    "    poesDF[\"ted_pro_total_flux\"] = poesRawData.variables['ted_pro_tel0_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_pro_tel0_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel0_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel0_flux_14'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_4'][:] +\\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_8'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_11'][:] + \\\n",
    "            poesRawData.variables['ted_pro_tel30_flux_14'][:]\n",
    "    poesDF['log_ele_flux'] = [0. if x <= 0. else round( numpy.log10(x), 2 )\\\n",
    "                 for x in poesDF['ted_ele_total_flux']]\n",
    "    poesDF['log_pro_flux'] = [0. if x <= 0. else round( numpy.log10(x), 2 )\\\n",
    "                 for x in poesDF['ted_pro_total_flux']]\n",
    "    # the current satellite number\n",
    "    poesDF[\"sat\"] = f[-19:-17]\n",
    "#     seperate out electron and proton flux and discard all zeros\n",
    "    currPoesEleFluxDF = poesDF[poesDF[\"log_ele_flux\"] > 0.][ [\"timestamp\",\\\n",
    "                     \"date\", \"aacgm_lat_foot\", \"aacgm_lon_foot\", \"MLT\",\\\n",
    "                     \"log_ele_flux\", \"sat\"] ].reset_index(drop=True)\n",
    "    currPoesProFluxDF = poesDF[poesDF[\"log_pro_flux\"] > 0.][ [\"timestamp\",\\\n",
    "                     \"date\", \"aacgm_lat_foot\", \"aacgm_lon_foot\", \"MLT\",\\\n",
    "                     \"log_pro_flux\", \"sat\"] ].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    poesAllEleDataDF = poesAllEleDataDF.append( currPoesEleFluxDF )\n",
    "    poesAllProDataDF = poesAllProDataDF.append( currPoesProFluxDF )\n",
    "    # now delete all the rows for prev DFs\n",
    "    # we don't want to duplicate data\n",
    "    poesDF = poesDF.drop( poesDF.index )\n",
    "    currPoesEleFluxDF = currPoesEleFluxDF.drop( currPoesEleFluxDF.index )\n",
    "    currPoesProFluxDF = currPoesProFluxDF.drop( currPoesProFluxDF.index )\n",
    "# create a date and time columns\n",
    "poesAllEleDataDF[\"dateStr\"] = poesAllEleDataDF[\"date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "poesAllEleDataDF[\"time\"] = poesAllEleDataDF[\"date\"].map(lambda x: x.strftime('%H%M'))\n",
    "poesAllProDataDF[\"dateStr\"] = poesAllProDataDF[\"date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "poesAllProDataDF[\"time\"] = poesAllProDataDF[\"date\"].map(lambda x: x.strftime('%H%M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-03-02 05:00:00.201000\n"
     ]
    }
   ],
   "source": [
    "timeRange = [ poesAllEleDataDF[\"date\"].min(), poesAllEleDataDF[\"date\"].max() ]\n",
    "ctime = timeRange[0]\n",
    "timeInterval=datetime.timedelta(minutes=30)\n",
    "while ctime <= timeRange[1]:\n",
    "    ctime += timeInterval\n",
    "    if abs( ctime - datetime.datetime(2013,3,2,5) ) < datetime.timedelta(minutes=1):\n",
    "        break\n",
    "print ctime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We only need those times when POES was above minCutoffFitLat(45) MLAT\n",
    "poesAllEleDataDF = poesAllEleDataDF[ \\\n",
    "                ( abs( poesAllEleDataDF[\"aacgm_lat_foot\"] ) >= minCutoffFitLat )\\\n",
    "                ].reset_index(drop=True)\n",
    "# We only need a few columns, discard the rest\n",
    "poesAllEleDataDF = poesAllEleDataDF[ [ 'sat', 'date',\\\n",
    "                        'aacgm_lat_foot', 'aacgm_lon_foot',\\\n",
    "                            'MLT', 'log_ele_flux' ] ]\n",
    "poesAllEleDataDF[\"delCtime\"] = abs(poesAllEleDataDF[\"date\"] - ctime)\n",
    "poesAllEleDataDF[\"delLatFit\"] = abs( poesAllEleDataDF[\"aacgm_lat_foot\"] ) -\\\n",
    "                                    abs( minCutoffFitLat )\n",
    "# We are sorting by sats, dates and lats to pick the nearest time\n",
    "# when the satellite is between two 45 MLATs\n",
    "poesAllEleDataDFNth = poesAllEleDataDF[ poesAllEleDataDF[\"aacgm_lat_foot\"]\\\n",
    "                        >= 0. ].sort_values( ['sat', 'date', 'aacgm_lat_foot'],\\\n",
    "                                ascending=True ).reset_index(drop=True).drop_duplicates()\n",
    "poesAllEleDataDFSth = poesAllEleDataDF[ poesAllEleDataDF[\"aacgm_lat_foot\"]\\\n",
    "                        < 0. ].sort_values( ['sat', 'date', 'aacgm_lat_foot'],\\\n",
    "                                ascending=True ).reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sat              start_time\n",
      "0  01 2013-03-02 05:09:26.746\n",
      "1  16 2013-03-02 04:55:20.987\n",
      "2  17 2013-03-02 04:21:50.193\n",
      "3  18 2013-03-02 05:14:07.132\n",
      "4  19 2013-03-02 05:08:44.993\n",
      "     sat                    date  aacgm_lat_foot\n",
      "6108  16 2013-03-02 04:55:20.987           45.29\n",
      "6109  16 2013-03-02 06:11:44.987           45.09\n",
      "6110  16 2013-03-02 06:11:50.987           45.37\n",
      "6111  16 2013-03-02 06:11:52.987           45.46\n",
      "6112  16 2013-03-02 06:11:58.988           45.74\n",
      "6113  16 2013-03-02 06:12:00.988           45.84\n",
      "6114  16 2013-03-02 06:12:08.987           46.21\n",
      "6115  16 2013-03-02 06:12:14.987           46.50\n",
      "6116  16 2013-03-02 06:12:16.987           46.59\n",
      "6117  16 2013-03-02 06:12:22.988           46.87\n",
      "6118  16 2013-03-02 06:12:24.988           46.97\n",
      "6119  16 2013-03-02 06:12:30.988           47.25\n",
      "6120  16 2013-03-02 06:12:32.988           47.34\n",
      "6121  16 2013-03-02 06:12:40.987           47.72\n",
      "6122  16 2013-03-02 06:12:46.988           48.00\n",
      "6123  16 2013-03-02 06:12:48.988           48.09\n",
      "6124  16 2013-03-02 06:12:56.988           48.47\n",
      "6125  16 2013-03-02 06:13:04.987           48.85\n",
      "6126  16 2013-03-02 06:13:12.988           49.23\n",
      "6127  16 2013-03-02 06:13:18.988           49.51\n",
      "6128  16 2013-03-02 06:13:20.988           49.60\n",
      "6129  16 2013-03-02 06:13:28.987           49.98\n",
      "6130  16 2013-03-02 06:13:34.987           50.27\n",
      "6131  16 2013-03-02 06:13:36.988           50.36\n",
      "6132  16 2013-03-02 06:13:42.988           50.65\n",
      "6133  16 2013-03-02 06:13:44.988           50.74\n",
      "6134  16 2013-03-02 06:13:50.987           51.03\n",
      "6135  16 2013-03-02 06:13:52.987           51.12\n",
      "6136  16 2013-03-02 06:14:00.987           51.50\n",
      "6137  16 2013-03-02 06:14:06.988           51.79\n",
      "...   ..                     ...             ...\n",
      "9374  16 2013-03-02 23:33:34.984           54.86\n",
      "9375  16 2013-03-02 23:33:36.984           54.75\n",
      "9376  16 2013-03-02 23:33:44.984           54.31\n",
      "9377  16 2013-03-02 23:33:52.983           53.87\n",
      "9378  16 2013-03-02 23:34:00.984           53.43\n",
      "9379  16 2013-03-02 23:34:06.984           53.10\n",
      "9380  16 2013-03-02 23:34:08.984           52.99\n",
      "9381  16 2013-03-02 23:34:14.983           52.67\n",
      "9382  16 2013-03-02 23:34:16.983           52.56\n",
      "9383  16 2013-03-02 23:34:24.984           52.12\n",
      "9384  16 2013-03-02 23:34:30.984           51.79\n",
      "9385  16 2013-03-02 23:34:32.984           51.68\n",
      "9386  16 2013-03-02 23:34:40.983           51.24\n",
      "9387  16 2013-03-02 23:34:48.983           50.80\n",
      "9388  16 2013-03-02 23:34:56.984           50.36\n",
      "9389  16 2013-03-02 23:35:04.983           49.92\n",
      "9390  16 2013-03-02 23:35:12.983           49.49\n",
      "9391  16 2013-03-02 23:35:20.984           49.05\n",
      "9392  16 2013-03-02 23:35:28.983           48.62\n",
      "9393  16 2013-03-02 23:35:36.983           48.19\n",
      "9394  16 2013-03-02 23:35:42.984           47.87\n",
      "9395  16 2013-03-02 23:35:44.984           47.76\n",
      "9396  16 2013-03-02 23:35:50.984           47.44\n",
      "9397  16 2013-03-02 23:35:52.984           47.33\n",
      "9398  16 2013-03-02 23:36:00.983           46.91\n",
      "9399  16 2013-03-02 23:36:06.984           46.59\n",
      "9400  16 2013-03-02 23:36:08.984           46.48\n",
      "9401  16 2013-03-02 23:36:16.984           46.06\n",
      "9402  16 2013-03-02 23:36:24.983           45.64\n",
      "9403  16 2013-03-02 23:36:32.984           45.21\n",
      "\n",
      "[3296 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Now we need to pick the satellite path (between two 45 MLATs)\n",
    "# which is closest to the selected time.!\n",
    "# Northern Hemisphere\n",
    "poesAllEleDataDFNthST = poesAllEleDataDFNth[ \\\n",
    "                            ( poesAllEleDataDFNth[\"delLatFit\"] <= delLatCutoff ) \\\n",
    "                            ].sort_values( [\"sat\",\"date\"], ascending=[True, True] )\n",
    "# We'll get the the satellite pass which is moving polewards\n",
    "# Basically percent change in latitudes should be negative\n",
    "# for a satellite moving polewards (percent change would help\n",
    "# with the southern hemisphere lcoations.)\n",
    "poesAllEleDataDFNthST[\"latRowDiffs\"] = poesAllEleDataDFNthST.groupby(\"sat\")[[\\\n",
    "                \"aacgm_lat_foot\" ] ].pct_change()\n",
    "poesAllEleDataDFNthST = poesAllEleDataDFNthST[\\\n",
    "                        poesAllEleDataDFNthST[\"latRowDiffs\"] < 0.\\\n",
    "                        ].sort_values( [\"sat\",\"delCtime\"] )\n",
    "# get the start time\n",
    "selTimeRangeNthDF = poesAllEleDataDFNthST.groupby(\"sat\").first().reset_index()\n",
    "# Now if the time difference is too large, discard the satellite data\n",
    "selTimeRangeNthDF = selTimeRangeNthDF[ selTimeRangeNthDF[\"delCtime\"] <= \\\n",
    "                    datetime.timedelta(minutes=delTimeCutOffNrstPass)\\\n",
    "                    ].reset_index()\n",
    "selTimeRangeNthDF = selTimeRangeNthDF[ [\"sat\", \"date\"] ]\n",
    "selTimeRangeNthDF.columns = [ \"sat\", \"start_time\" ]\n",
    "print selTimeRangeNthDF\n",
    "# Now get the end times, simply get all times that are\n",
    "# greater than start time, sort them by date and get\n",
    "# lowest deLatFit\n",
    "poesAllEleDataDFNthET = pandas.merge( poesAllEleDataDFNth,\\\n",
    "                            selTimeRangeNthDF, on=\"sat\" )\n",
    "poesAllEleDataDFNthET = poesAllEleDataDFNthET[ (\\\n",
    "                                poesAllEleDataDFNthET[\"date\"] >=\\\n",
    "                                poesAllEleDataDFNthET[\"start_time\"] ) ]\n",
    "print poesAllEleDataDFNthET[ \\\n",
    "        poesAllEleDataDFNthET[\"sat\"] == \"16\" \\\n",
    "        ][ [ \"sat\", \"date\", \"aacgm_lat_foot\" ] ].sort_values( [\"date\"] )\n",
    "# We'll get the the satellite pass which is moving equatorwards\n",
    "# Basically percent change in latitudes should AALLSSOO be negative\n",
    "# Negative because of the index! Its wierd i know!\n",
    "# for a satellite moving equatorwards (percent change would help\n",
    "# with the southern hemisphere lcoations.)\n",
    "poesAllEleDataDFNthET[\"latRowDiffs\"] = poesAllEleDataDFNthET.groupby(\"sat\")[[\\\n",
    "                \"aacgm_lat_foot\" ] ].pct_change()\n",
    "\n",
    "# poesAllEleDataDFNthET = poesAllEleDataDFNthET[\\\n",
    "#                         (poesAllEleDataDFNthET[\"latRowDiffs\"] < 0.) &\\\n",
    "#                         ( poesAllEleDataDFNthET[\"delLatFit\"] <= delLatCutoff )\n",
    "#                         ].sort_values( [\"sat\",\"delCtime\"] )\n",
    "\n",
    "# # get the end time\n",
    "# eTimeNthDF = poesAllEleDataDFNthET.groupby(\"sat\").first().reset_index()\n",
    "# eTimeNthDF = eTimeNthDF[ [\"sat\", \"date\"] ]\n",
    "# eTimeNthDF.columns = [ \"sat\", \"end_time\" ]\n",
    "# selTimeRangeNthDF = pandas.merge( selTimeRangeNthDF, eTimeNthDF,\\\n",
    "#                                 on=\"sat\")\n",
    "# selTimeRangeNthDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sat              start_time\n",
      "0  01 2013-03-02 04:17:58.750\n",
      "1  16 2013-03-02 05:18:30.988\n",
      "2  17 2013-03-02 04:45:50.194\n",
      "3  18 2013-03-02 04:25:37.132\n",
      "4  19 2013-03-02 05:35:58.993\n"
     ]
    }
   ],
   "source": [
    "# Now we need to pick the satellite path (between two 45 MLATs)\n",
    "# which is closest to the selected time.!\n",
    "# Southern Hemisphere\n",
    "poesAllEleDataDFSthST = poesAllEleDataDFSth[ \\\n",
    "                            ( poesAllEleDataDFSth[\"delLatFit\"] <= delLatCutoff ) \\\n",
    "                            ].sort_values( [\"sat\",\"date\"], ascending=[True, True] )\n",
    "# We'll get the the satellite which is moving polewards\n",
    "# Basically percent change in latitudes should be postive\n",
    "# for a satellite moving polewards (percent change would help\n",
    "# with the southern hemisphere lcoations.)\n",
    "poesAllEleDataDFSthST[\"latRowDiffs\"] = poesAllEleDataDFSthST.groupby(\"sat\")[[\\\n",
    "                \"aacgm_lat_foot\" ] ].pct_change()\n",
    "poesAllEleDataDFSthST = poesAllEleDataDFSthST[\\\n",
    "                        poesAllEleDataDFSthST[\"latRowDiffs\"] > 0.\\\n",
    "                        ].sort_values( [\"sat\",\"delCtime\"] )\n",
    "# get the start time\n",
    "selTimeRangeSthDF = poesAllEleDataDFSthST.groupby(\"sat\").first().reset_index()\n",
    "# Now if the time difference is too large, discard the satellite data\n",
    "selTimeRangeSthDF = selTimeRangeSthDF[ selTimeRangeSthDF[\"delCtime\"] <= \\\n",
    "                    datetime.timedelta(minutes=delTimeCutOffNrstPass)\\\n",
    "                    ].reset_index()\n",
    "selTimeRangeSthDF = selTimeRangeSthDF[ [\"sat\", \"date\"] ]\n",
    "selTimeRangeSthDF.columns = [ \"sat\", \"start_time\" ]\n",
    "# Now get the end times, simply get all times that are\n",
    "# greater than start time, sort them by date and get\n",
    "# lowest deLatFit\n",
    "print selTimeRangeSthDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
