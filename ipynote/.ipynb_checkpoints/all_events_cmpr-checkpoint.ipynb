{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "import time\n",
    "import bs4\n",
    "import urllib\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dst_date  dst_index\n",
       "0 2011-01-01 01:00:00      -11.0\n",
       "1 2011-01-01 02:00:00      -11.0\n",
       "2 2011-01-01 03:00:00       -9.0\n",
       "3 2011-01-01 04:00:00       -5.0\n",
       "4 2011-01-01 05:00:00       -3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dst index vals from wdc kyoto website\n",
    "# create a list of dates with monthly freq\n",
    "date_dst_arr = []\n",
    "dst_val = []\n",
    "dst_time_del = datetime.timedelta(hours = 1)\n",
    "start_date = datetime.datetime(2011,1,1)\n",
    "end_date = datetime.datetime(2014,12,31)\n",
    "daterange = pandas.date_range(start_date, end_date, freq=\"M\")\n",
    "for dt in daterange:\n",
    "    if dt.month <= 9:\n",
    "            monthStr = \"0\" + str(dt.month)\n",
    "    else:\n",
    "        monthStr = str(dt.month)\n",
    "    if dt.year >= 2015:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_realtime\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    elif ( (dt.year > 2011) and (dt.year < 2015) ):\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_provisional\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    else:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_final\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    conn = urllib.urlopen(currUrl)\n",
    "    htmlSource = conn.read()\n",
    "    soup = bs4.BeautifulSoup(htmlSource, 'html.parser')\n",
    "    dataResObj = soup.find(\"pre\", { \"class\" : \"data\" })\n",
    "    # get the data as a list of strings after removing white space\n",
    "    lines = dataResObj.text.strip().splitlines()\n",
    "    for line in lines[6:]:\n",
    "        columns = line.split()\n",
    "        if len( columns ) > 0. :\n",
    "            date_dst_arr.append( datetime.datetime( \\\n",
    "                dt.year, dt.month, int(columns[0]), 1 ) )\n",
    "            for cols in range( len( columns[1:] ) ) :\n",
    "                try:\n",
    "                    inNumberFloatTest = float(columns[cols + 1])\n",
    "                except:\n",
    "                    # split these cols as well and work on them!\n",
    "                    try:\n",
    "                        missedCols = columns[cols + 1].split(\"-\")[1:]\n",
    "                        if len(missedCols) >= 1:\n",
    "                            for mcols in missedCols:\n",
    "                                dst_val.append( -1*float( mcols ) )\n",
    "                                # now since we added the date earlier we need to be\n",
    "                                # careful about appending date values\n",
    "                                if ( len(date_dst_arr) != len(dst_val) ):\n",
    "                                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "                    except:\n",
    "                        print \"something wrong with messed up vals!-->\", columns[cols + 1]\n",
    "                        continue\n",
    "                    continue\n",
    "                # I have to do this because of the messed up way Kyoto puts up the latest dst value..\n",
    "                # mixed with 9999 (fillers) like if latest dst is 1 then Kyoto puts it as 199999.....\n",
    "                if len( columns[ cols + 1 ] ) < 5 :\n",
    "                    dst_val.append( float( columns[ cols + 1 ] ) )\n",
    "                elif ( len( columns[ cols + 1 ] ) > 5 and columns[ cols + 1 ][0:3] != '999' ) :\n",
    "                    mixed_messed_dst = ''\n",
    "                    for jj in range(5) :\n",
    "                        if columns[ cols + 1 ][jj] != '9' :\n",
    "                            mixed_messed_dst = mixed_messed_dst + columns[ cols + 1 ][jj]\n",
    "\n",
    "                    if mixed_messed_dst != '-' :\n",
    "                        dst_val.append( float( mixed_messed_dst ) )\n",
    "                    else :\n",
    "                        dst_val.append( float( 'nan' ) )\n",
    "                else :\n",
    "                    dst_val.append( float( 'nan' ) )\n",
    "                if cols > 0 :\n",
    "                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "# convert dst data to a dataframe\n",
    "dstDF = pandas.DataFrame(\n",
    "    {'dst_date': date_dst_arr,\n",
    "     'dst_index': dst_val\n",
    "    })\n",
    "dstDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of unique(total) dates---> 1320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTimeString</th>\n",
       "      <th>date</th>\n",
       "      <th>dateStr</th>\n",
       "      <th>sapsLat</th>\n",
       "      <th>sapsMLT</th>\n",
       "      <th>sapsVel</th>\n",
       "      <th>radId</th>\n",
       "      <th>poesLat</th>\n",
       "      <th>poesMLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20110101-100</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>61.5</td>\n",
       "      <td>2.7764</td>\n",
       "      <td>336.5572</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.4015</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20110101-230</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>61.5</td>\n",
       "      <td>4.5593</td>\n",
       "      <td>254.1402</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.2104</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1.7927</td>\n",
       "      <td>639.8867</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>650.9573</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.8949</td>\n",
       "      <td>653.0461</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dateTimeString                date   dateStr  sapsLat  sapsMLT   sapsVel  \\\n",
       "0   20110101-100 2011-01-01 01:00:00  20110101     61.5   2.7764  336.5572   \n",
       "1   20110101-230 2011-01-01 02:30:00  20110101     61.5   4.5593  254.1402   \n",
       "2   20110101-700 2011-01-01 07:00:00  20110101     54.5   1.7927  639.8867   \n",
       "3   20110101-700 2011-01-01 07:00:00  20110101     54.5   1.9076  650.9573   \n",
       "4   20110101-700 2011-01-01 07:00:00  20110101     55.5   1.8949  653.0461   \n",
       "\n",
       "   radId  poesLat  poesMLT  \n",
       "0   10.0  65.4015      3.0  \n",
       "1   10.0  66.2104      5.0  \n",
       "2   33.0  67.2811      2.0  \n",
       "3   33.0  67.2811      2.0  \n",
       "4   33.0  67.2811      2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file containing saps data --> date, time, sapsLat, sapsMLT, sapsVel, radId, poesLat, poesMLT\n",
    "#file_sapsdata = \"/Users/bharat/Desktop/saps-north-2011-2012.txt\"\n",
    "file_sapsdata = \"../data/rawsaps-north-2011-2014.txt\"\n",
    "# store the data to convert it to DF later\n",
    "allData = []\n",
    "# open and read through the file\n",
    "fs = open(file_sapsdata, 'r')\n",
    "# only take data from mid-latitude radars\n",
    "midlatRadIds = [209, 208, 33, 207, 206, 205, 204, 32]\n",
    "for line in fs:\n",
    "    line = line.strip()\n",
    "    columns = line.split()\n",
    "    \n",
    "    dt_ind = time.strptime( columns[0], \"%Y%m%d\" )\n",
    "    hh_ind = int(int(columns[1])/100)\n",
    "    mm_ind = int(int(columns[1]) % 100)\n",
    "    currDt = datetime.datetime( dt_ind.tm_year, dt_ind.tm_mon, dt_ind.tm_mday, hh_ind, mm_ind )\n",
    "    allData.append( [ columns[0] + \"-\" + columns[1], currDt, columns[0], \\\n",
    "                     float( columns[2] ), float( columns[3] ), float( columns[4] ), \\\n",
    "                     float( columns[5] ), float( columns[6] ), float( columns[7] ) ] )  \n",
    "fs.close()\n",
    "# store data in a DF\n",
    "sapsRawDF = pandas.DataFrame(allData)\n",
    "sapsRawDF.columns = [ \"dateTimeString\", \"date\", \"dateStr\", \"sapsLat\", \\\n",
    "                     \"sapsMLT\", \"sapsVel\", \"radId\", \"poesLat\", \"poesMLT\" ]\n",
    "# count number of unique dates present in the raw DF\n",
    "uniqSapsDates = sapsRawDF[\"dateStr\"].unique().tolist()\n",
    "print \"num of unique(total) dates--->\", len(uniqSapsDates)\n",
    "sapsRawDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0                   1         2     3    4         5     6  \\\n",
      "0  20110101-200 2011-01-01 02:00:00  20110101  53.5 -1.0  198.2172  33.0   \n",
      "1  20110101-700 2011-01-01 07:00:00  20110101  54.5 -1.0  639.8867  33.0   \n",
      "2  20110101-700 2011-01-01 07:00:00  20110101  54.5 -1.0  650.9573  33.0   \n",
      "3  20110101-700 2011-01-01 07:00:00  20110101  55.5 -1.0  653.0461  33.0   \n",
      "4  20110101-700 2011-01-01 07:00:00  20110101  53.5 -1.0  638.6191  33.0   \n",
      "\n",
      "      7     8  \n",
      "0  90.0  90.0  \n",
      "1  90.0  90.0  \n",
      "2  90.0  90.0  \n",
      "3  90.0  90.0  \n",
      "4  90.0  90.0  \n",
      "num of unique(total) dates---> 1320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTimeString</th>\n",
       "      <th>date</th>\n",
       "      <th>dateStr</th>\n",
       "      <th>sapsLat</th>\n",
       "      <th>sapsMLT</th>\n",
       "      <th>sapsVel</th>\n",
       "      <th>radId</th>\n",
       "      <th>poesLat</th>\n",
       "      <th>poesMLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20110101-200</td>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>53.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>198.2172</td>\n",
       "      <td>33.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>639.8867</td>\n",
       "      <td>33.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>650.9573</td>\n",
       "      <td>33.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>55.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>653.0461</td>\n",
       "      <td>33.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>53.5</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>638.6191</td>\n",
       "      <td>33.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dateTimeString                date   dateStr  sapsLat  sapsMLT   sapsVel  \\\n",
       "0   20110101-200 2011-01-01 02:00:00  20110101     53.5     -1.0  198.2172   \n",
       "1   20110101-700 2011-01-01 07:00:00  20110101     54.5     -1.0  639.8867   \n",
       "2   20110101-700 2011-01-01 07:00:00  20110101     54.5     -1.0  650.9573   \n",
       "3   20110101-700 2011-01-01 07:00:00  20110101     55.5     -1.0  653.0461   \n",
       "4   20110101-700 2011-01-01 07:00:00  20110101     53.5     -1.0  638.6191   \n",
       "\n",
       "   radId  poesLat  poesMLT  \n",
       "0   33.0     90.0     90.0  \n",
       "1   33.0     90.0     90.0  \n",
       "2   33.0     90.0     90.0  \n",
       "3   33.0     90.0     90.0  \n",
       "4   33.0     90.0     90.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_alldata = \"/home/bharat/Documents/data/filtered-mid-lat-data-north-2011-2014.txt\"\n",
    "allData = []\n",
    "# open and read through the file\n",
    "fs = open(file_alldata, 'r')\n",
    "for line in fs:\n",
    "    line = line.strip()\n",
    "    columns = line.split()\n",
    "    \n",
    "    dt_ind = time.strptime( columns[0], \"%Y%m%d\" )\n",
    "    hh_ind = int(int(columns[1])/100)\n",
    "    mm_ind = int(int(columns[1]) % 100)\n",
    "    currDt = datetime.datetime( dt_ind.tm_year, dt_ind.tm_mon, dt_ind.tm_mday, hh_ind, mm_ind )\n",
    "    # Only choose SAPS dates\n",
    "    if columns[0] not in uniqSapsDates:\n",
    "        continue\n",
    "    if len(columns) != 8:\n",
    "        print \"wrong!!!-->\", columns\n",
    "        print \"--------------------------------------\"\n",
    "        print line\n",
    "    allData.append( [ columns[0] + \"-\" + columns[1], currDt, columns[0], \\\n",
    "                     float( columns[2] ), float( columns[3] ), float( columns[4] ), \\\n",
    "                     float( columns[5] ), float( columns[6] ), float( columns[7] ) ] )  \n",
    "fs.close()\n",
    "allRawDF = pandas.DataFrame(allData)\n",
    "allRawDF.columns = [ \"dateTimeString\", \"date\", \"dateStr\", \"sapsLat\", \\\n",
    "                     \"sapsMLT\", \"sapsVel\", \"radId\", \"poesLat\", \"poesMLT\" ]\n",
    "# count number of unique dates present in the raw DF\n",
    "uniqRawDates = allRawDF[\"dateStr\"].unique().tolist()\n",
    "print \"num of unique(total) dates--->\", len(uniqRawDates)\n",
    "allRawDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f5c6c71ff9ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Instead of the daywise thing we'll do an hourwise analysis too!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfullDatesDstGrps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallRawDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dateStr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hour\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mminDstFullDataHourwise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullDatesDstGrps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dst_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mminDstAllDataHourwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Below is just a sanity check to verify the joins are working fine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   3989\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   3990\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3991\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   3992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[1;32m   2460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2461\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# df.groupby('name')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2462\u001b[0;31m             \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2463\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2464\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGrouper\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2057\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2064\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2065\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2066\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2068\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3542\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3543\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3544\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3545\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2134\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2136\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4433)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4279)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13742)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13696)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hour'"
     ]
    }
   ],
   "source": [
    "# Instead of the daywise thing we'll do an hourwise analysis too!\n",
    "fullDatesDstGrps = allRawDF.groupby([\"dateStr\", \"hour\"])\n",
    "minDstFullDataHourwise = fullDatesDstGrps[\"dst_index\"].aggregate(lambda x: set(tuple(x))).reset_index()\n",
    "# print minDstAllDataHourwise\n",
    "# Below is just a sanity check to verify the joins are working fine\n",
    "# Basically we shouldn't have more than 1 Dst index\n",
    "minDstFullDataHourwise[\"checkSameDst\"] = minDstFullDataHourwise[\"dst_index\"].map(\\\n",
    "                                    lambda x: len(x) > 1 )\n",
    "if (minDstFullDataHourwise[ minDstFullDataHourwise[ \"checkSameDst\" ] == True ][\"dst_index\"].count() == 0):\n",
    "    print \"JOIN WENT WELL LOOKE FINE!\"\n",
    "else:\n",
    "    print \"NEED TO CHECK THE CODE! MAJORRRR PROBLEMMMMM!\"\n",
    "minDstFullDataHourwise[\"dst_index\"] = minDstFullDataHourwise[\"dst_index\"].map(\\\n",
    "                                    lambda x: x.pop() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
