{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import datetime\n",
    "import numpy\n",
    "import time\n",
    "import bs4\n",
    "import urllib\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-01 05:00:00</td>\n",
       "      <td>-3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             dst_date  dst_index\n",
       "0 2011-01-01 01:00:00      -11.0\n",
       "1 2011-01-01 02:00:00      -11.0\n",
       "2 2011-01-01 03:00:00       -9.0\n",
       "3 2011-01-01 04:00:00       -5.0\n",
       "4 2011-01-01 05:00:00       -3.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dst index vals from wdc kyoto website\n",
    "# create a list of dates with monthly freq\n",
    "date_dst_arr = []\n",
    "dst_val = []\n",
    "dst_time_del = datetime.timedelta(hours = 1)\n",
    "start_date = datetime.datetime(2011,1,1)\n",
    "end_date = datetime.datetime(2014,12,31)\n",
    "daterange = pandas.date_range(start_date, end_date, freq=\"M\")\n",
    "for dt in daterange:\n",
    "    if dt.month <= 9:\n",
    "            monthStr = \"0\" + str(dt.month)\n",
    "    else:\n",
    "        monthStr = str(dt.month)\n",
    "    if dt.year >= 2015:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_realtime\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    elif ( (dt.year > 2011) and (dt.year < 2015) ):\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_provisional\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    else:\n",
    "        # create the url\n",
    "        currUrl = \"http://wdc.kugi.kyoto-u.ac.jp/\" + \"dst_final\" + \\\n",
    "            \"/\" + str(dt.year) + monthStr + \"/index.html\"\n",
    "    conn = urllib.urlopen(currUrl)\n",
    "    htmlSource = conn.read()\n",
    "    soup = bs4.BeautifulSoup(htmlSource, 'html.parser')\n",
    "    dataResObj = soup.find(\"pre\", { \"class\" : \"data\" })\n",
    "    # get the data as a list of strings after removing white space\n",
    "    lines = dataResObj.text.strip().splitlines()\n",
    "    for line in lines[6:]:\n",
    "        columns = line.split()\n",
    "        if len( columns ) > 0. :\n",
    "            date_dst_arr.append( datetime.datetime( \\\n",
    "                dt.year, dt.month, int(columns[0]), 1 ) )\n",
    "            for cols in range( len( columns[1:] ) ) :\n",
    "                try:\n",
    "                    inNumberFloatTest = float(columns[cols + 1])\n",
    "                except:\n",
    "                    # split these cols as well and work on them!\n",
    "                    try:\n",
    "                        missedCols = columns[cols + 1].split(\"-\")[1:]\n",
    "                        if len(missedCols) >= 1:\n",
    "                            for mcols in missedCols:\n",
    "                                dst_val.append( -1*float( mcols ) )\n",
    "                                # now since we added the date earlier we need to be\n",
    "                                # careful about appending date values\n",
    "                                if ( len(date_dst_arr) != len(dst_val) ):\n",
    "                                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "                    except:\n",
    "                        print \"something wrong with messed up vals!-->\", columns[cols + 1]\n",
    "                        continue\n",
    "                    continue\n",
    "                # I have to do this because of the messed up way Kyoto puts up the latest dst value..\n",
    "                # mixed with 9999 (fillers) like if latest dst is 1 then Kyoto puts it as 199999.....\n",
    "                if len( columns[ cols + 1 ] ) < 5 :\n",
    "                    dst_val.append( float( columns[ cols + 1 ] ) )\n",
    "                elif ( len( columns[ cols + 1 ] ) > 5 and columns[ cols + 1 ][0:3] != '999' ) :\n",
    "                    mixed_messed_dst = ''\n",
    "                    for jj in range(5) :\n",
    "                        if columns[ cols + 1 ][jj] != '9' :\n",
    "                            mixed_messed_dst = mixed_messed_dst + columns[ cols + 1 ][jj]\n",
    "\n",
    "                    if mixed_messed_dst != '-' :\n",
    "                        dst_val.append( float( mixed_messed_dst ) )\n",
    "                    else :\n",
    "                        dst_val.append( float( 'nan' ) )\n",
    "                else :\n",
    "                    dst_val.append( float( 'nan' ) )\n",
    "                if cols > 0 :\n",
    "                    date_dst_arr.append ( date_dst_arr[-1] + dst_time_del )\n",
    "# convert dst data to a dataframe\n",
    "dstDF = pandas.DataFrame(\n",
    "    {'dst_date': date_dst_arr,\n",
    "     'dst_index': dst_val\n",
    "    })\n",
    "dstDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of unique(total) dates---> 1320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTimeString</th>\n",
       "      <th>date</th>\n",
       "      <th>dateStr</th>\n",
       "      <th>sapsLat</th>\n",
       "      <th>sapsMLT</th>\n",
       "      <th>sapsVel</th>\n",
       "      <th>radId</th>\n",
       "      <th>poesLat</th>\n",
       "      <th>poesMLT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20110101-100</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>61.5</td>\n",
       "      <td>2.7764</td>\n",
       "      <td>336.5572</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.4015</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20110101-230</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>61.5</td>\n",
       "      <td>4.5593</td>\n",
       "      <td>254.1402</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.2104</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1.7927</td>\n",
       "      <td>639.8867</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>650.9573</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.8949</td>\n",
       "      <td>653.0461</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dateTimeString                date   dateStr  sapsLat  sapsMLT   sapsVel  \\\n",
       "0   20110101-100 2011-01-01 01:00:00  20110101     61.5   2.7764  336.5572   \n",
       "1   20110101-230 2011-01-01 02:30:00  20110101     61.5   4.5593  254.1402   \n",
       "2   20110101-700 2011-01-01 07:00:00  20110101     54.5   1.7927  639.8867   \n",
       "3   20110101-700 2011-01-01 07:00:00  20110101     54.5   1.9076  650.9573   \n",
       "4   20110101-700 2011-01-01 07:00:00  20110101     55.5   1.8949  653.0461   \n",
       "\n",
       "   radId  poesLat  poesMLT  \n",
       "0   10.0  65.4015      3.0  \n",
       "1   10.0  66.2104      5.0  \n",
       "2   33.0  67.2811      2.0  \n",
       "3   33.0  67.2811      2.0  \n",
       "4   33.0  67.2811      2.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# file containing saps data --> date, time, sapsLat, sapsMLT, sapsVel, radId, poesLat, poesMLT\n",
    "#file_sapsdata = \"/Users/bharat/Desktop/saps-north-2011-2012.txt\"\n",
    "file_sapsdata = \"../data/rawsaps-north-2011-2014.txt\"\n",
    "# store the data to convert it to DF later\n",
    "allData = []\n",
    "# open and read through the file\n",
    "fs = open(file_sapsdata, 'r')\n",
    "# only take data from mid-latitude radars\n",
    "midlatRadIds = [209, 208, 33, 207, 206, 205, 204, 32]\n",
    "for line in fs:\n",
    "    line = line.strip()\n",
    "    columns = line.split()\n",
    "    \n",
    "    dt_ind = time.strptime( columns[0], \"%Y%m%d\" )\n",
    "    hh_ind = int(int(columns[1])/100)\n",
    "    mm_ind = int(int(columns[1]) % 100)\n",
    "    currDt = datetime.datetime( dt_ind.tm_year, dt_ind.tm_mon, dt_ind.tm_mday, hh_ind, mm_ind )\n",
    "    allData.append( [ columns[0] + \"-\" + columns[1], currDt, columns[0], \\\n",
    "                     float( columns[2] ), float( columns[3] ), float( columns[4] ), \\\n",
    "                     float( columns[5] ), float( columns[6] ), float( columns[7] ) ] )  \n",
    "fs.close()\n",
    "# store data in a DF\n",
    "sapsRawDF = pandas.DataFrame(allData)\n",
    "sapsRawDF.columns = [ \"dateTimeString\", \"date\", \"dateStr\", \"sapsLat\", \\\n",
    "                     \"sapsMLT\", \"sapsVel\", \"radId\", \"poesLat\", \"poesMLT\" ]\n",
    "# count number of unique dates present in the raw DF\n",
    "uniqRawDates = sapsRawDF[\"dateStr\"].unique().tolist()\n",
    "print \"num of unique(total) dates--->\", len(uniqRawDates)\n",
    "sapsRawDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateTimeString</th>\n",
       "      <th>date</th>\n",
       "      <th>dateStr</th>\n",
       "      <th>sapsLat</th>\n",
       "      <th>sapsMLT</th>\n",
       "      <th>sapsVel</th>\n",
       "      <th>radId</th>\n",
       "      <th>poesLat</th>\n",
       "      <th>poesMLT</th>\n",
       "      <th>hour</th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20110101-100</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>61.5</td>\n",
       "      <td>2.7764</td>\n",
       "      <td>336.5572</td>\n",
       "      <td>10.0</td>\n",
       "      <td>65.4015</td>\n",
       "      <td>3.0</td>\n",
       "      <td>01</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20110101-230</td>\n",
       "      <td>2011-01-01 02:30:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>61.5</td>\n",
       "      <td>4.5593</td>\n",
       "      <td>254.1402</td>\n",
       "      <td>10.0</td>\n",
       "      <td>66.2104</td>\n",
       "      <td>5.0</td>\n",
       "      <td>02</td>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "      <td>-11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1.7927</td>\n",
       "      <td>639.8867</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "      <td>07</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>54.5</td>\n",
       "      <td>1.9076</td>\n",
       "      <td>650.9573</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "      <td>07</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20110101-700</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>20110101</td>\n",
       "      <td>55.5</td>\n",
       "      <td>1.8949</td>\n",
       "      <td>653.0461</td>\n",
       "      <td>33.0</td>\n",
       "      <td>67.2811</td>\n",
       "      <td>2.0</td>\n",
       "      <td>07</td>\n",
       "      <td>2011-01-01 07:00:00</td>\n",
       "      <td>-5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dateTimeString                date   dateStr  sapsLat  sapsMLT   sapsVel  \\\n",
       "0   20110101-100 2011-01-01 01:00:00  20110101     61.5   2.7764  336.5572   \n",
       "1   20110101-230 2011-01-01 02:30:00  20110101     61.5   4.5593  254.1402   \n",
       "2   20110101-700 2011-01-01 07:00:00  20110101     54.5   1.7927  639.8867   \n",
       "3   20110101-700 2011-01-01 07:00:00  20110101     54.5   1.9076  650.9573   \n",
       "4   20110101-700 2011-01-01 07:00:00  20110101     55.5   1.8949  653.0461   \n",
       "\n",
       "   radId  poesLat  poesMLT hour            dst_date  dst_index  \n",
       "0   10.0  65.4015      3.0   01 2011-01-01 01:00:00      -11.0  \n",
       "1   10.0  66.2104      5.0   02 2011-01-01 02:00:00      -11.0  \n",
       "2   33.0  67.2811      2.0   07 2011-01-01 07:00:00       -5.0  \n",
       "3   33.0  67.2811      2.0   07 2011-01-01 07:00:00       -5.0  \n",
       "4   33.0  67.2811      2.0   07 2011-01-01 07:00:00       -5.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a date string and time column for the dst DF\n",
    "dstDF[\"dateStr\"] = dstDF[\"dst_date\"].map(lambda x: x.strftime('%Y%m%d'))\n",
    "dstDF[\"hour\"] = dstDF[\"dst_date\"].map(lambda x: x.strftime('%H'))\n",
    "# Make an hour column for the sapsRawDF too\n",
    "sapsRawDF[\"hour\"] = sapsRawDF[\"date\"].map(lambda x: x.strftime('%H'))\n",
    "# Now merge the dst and sapsRaw DFs\n",
    "sapsRawDF = pandas.merge( sapsRawDF, dstDF, on=[\"dateStr\", \"hour\"], how='inner')\n",
    "sapsRawDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of saps dates---> 1320\n",
      "(-10, 10]      553\n",
      "(-25, -10]     455\n",
      "(-50, -25]     212\n",
      "(-75, -50]      51\n",
      "(-150, -75]     24\n",
      "Name: dst_index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get dst wise days\n",
    "# count number of (saps) dates present in the processed DF\n",
    "uniqTotalDates = sapsRawDF[\"dateStr\"].unique().tolist()\n",
    "print \"num of saps dates--->\", len(uniqTotalDates)\n",
    "# get daywise min Dst\n",
    "allDatesDstGrps = sapsRawDF.groupby([\"dateStr\"])\n",
    "minDstAllDataDaywise = allDatesDstGrps[\"dst_index\"].min()\n",
    "# We'll use the pandas cut function to bin the data\n",
    "# our bins are --> [-10,10], [-25,-10], [-50,-25], [-75,-50], [-125,-75]\n",
    "bins = [-150,-75,-50,-25,-10,10]\n",
    "allDataDayWiseBins = pandas.cut( minDstAllDataDaywise, bins=bins )\n",
    "print pandas.value_counts( allDataDayWiseBins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOIN WENT WELL LOOKE FINE!\n"
     ]
    }
   ],
   "source": [
    "# Instead of the daywise thing we'll do an hourwise analysis too!\n",
    "allDatesDstGrps = sapsRawDF.groupby([\"dateStr\", \"hour\"])\n",
    "minDstAllDataHourwise = allDatesDstGrps[\"dst_index\"].aggregate(lambda x: set(tuple(x))).reset_index()\n",
    "# Below is just a sanity check to verify the joins are working fine\n",
    "# Basically we shouldn't have more than 1 Dst index\n",
    "minDstAllDataHourwise[\"checkSameDst\"] = minDstAllDataHourwise[\"dst_index\"].map(\\\n",
    "                                    lambda x: len(x) > 1 )\n",
    "if (minDstAllDataHourwise[ minDstAllDataHourwise[ \"checkSameDst\" ] == True ][\"dst_index\"].count() == 0):\n",
    "    print \"JOIN WENT WELL LOOKE FINE!\"\n",
    "else:\n",
    "    print \"NEED TO CHECK THE CODE! MAJORRRR PROBLEMMMMM!\"\n",
    "minDstAllDataHourwise[\"dst_index\"] = minDstAllDataHourwise[\"dst_index\"].map(\\\n",
    "                                    lambda x: x.pop() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-10, 10]      14974\n",
      "(-25, -10]      3067\n",
      "(-50, -25]      1410\n",
      "(-75, -50]       265\n",
      "(-150, -75]      133\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "allDataHourWiseBins = pandas.cut( minDstAllDataHourwise, bins=bins )\n",
    "print pandas.value_counts( allDataHourWiseBins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateStr</th>\n",
       "      <th>sapsLat</th>\n",
       "      <th>sapsMLT</th>\n",
       "      <th>sapsVel</th>\n",
       "      <th>radId</th>\n",
       "      <th>poesLat</th>\n",
       "      <th>poesMLT</th>\n",
       "      <th>dst_date</th>\n",
       "      <th>dst_index</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20110107</td>\n",
       "      <td>56.5</td>\n",
       "      <td>17.7543</td>\n",
       "      <td>308.2077</td>\n",
       "      <td>33.0</td>\n",
       "      <td>62.0082</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20110107</td>\n",
       "      <td>55.5</td>\n",
       "      <td>18.0147</td>\n",
       "      <td>224.1588</td>\n",
       "      <td>33.0</td>\n",
       "      <td>62.0082</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20110107</td>\n",
       "      <td>56.5</td>\n",
       "      <td>17.8749</td>\n",
       "      <td>307.4328</td>\n",
       "      <td>33.0</td>\n",
       "      <td>62.0082</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20110107</td>\n",
       "      <td>55.5</td>\n",
       "      <td>18.1324</td>\n",
       "      <td>222.4787</td>\n",
       "      <td>33.0</td>\n",
       "      <td>62.0082</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20110107</td>\n",
       "      <td>56.5</td>\n",
       "      <td>17.9955</td>\n",
       "      <td>305.4201</td>\n",
       "      <td>33.0</td>\n",
       "      <td>62.0082</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2011-01-07</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dateStr  sapsLat  sapsMLT   sapsVel  radId  poesLat  poesMLT   dst_date  \\\n",
       "0  20110107     56.5  17.7543  308.2077   33.0  62.0082     18.0 2011-01-07   \n",
       "1  20110107     55.5  18.0147  224.1588   33.0  62.0082     18.0 2011-01-07   \n",
       "2  20110107     56.5  17.8749  307.4328   33.0  62.0082     18.0 2011-01-07   \n",
       "3  20110107     55.5  18.1324  222.4787   33.0  62.0082     18.0 2011-01-07   \n",
       "4  20110107     56.5  17.9955  305.4201   33.0  62.0082     18.0 2011-01-07   \n",
       "\n",
       "   dst_index  time  \n",
       "0      -18.0  0000  \n",
       "1      -18.0  0000  \n",
       "2      -18.0  0000  \n",
       "3      -18.0  0000  \n",
       "4      -18.0  0000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Try a new method to filter for the SAPS events\n",
    "# # Involves 3 filters : \n",
    "# # 1) get data from only mid-lat radars\n",
    "sapsRawDF = sapsRawDF[ sapsRawDF[\"radId\"].isin(midlatRadIds) ]\n",
    "sapsRawDF = sapsRawDF[ sapsRawDF[\"dst_index\"] <= 10.] \n",
    "# # 2) The saps event should be observed by atleast 4 mid-latitude radars on a given day\n",
    "sapsNumRadsSer = sapsRawDF.groupby( [\"dateStr\"] ).agg( {\"radId\": pandas.Series.nunique} )\n",
    "sapsNumRadsSer = sapsNumRadsSer[ sapsNumRadsSer >= 4  ].dropna().reset_index()\n",
    "sapsNumRadsSer.columns = [ \"dateStr\", \"nRads\" ]\n",
    "# Number of data points on a given date should be greater than 200!\n",
    "sapsDateTimeCount = sapsRawDF.groupby([\"dateStr\"]).count()\n",
    "sapsDateTimeCount = sapsDateTimeCount[ \\\n",
    "                        sapsDateTimeCount[\"sapsLat\"] >= 200 ][ [\"dateTimeString\"] ].reset_index()\n",
    "sapsDateTimeCount.columns = [ \"dateStr\", \"nSapsVecs\" ]\n",
    "# Merge both the data points\n",
    "sapsDateSelDF = pandas.merge( sapsDateTimeCount, sapsNumRadsSer, on=\"dateStr\" )\n",
    "# Now merge dates selected and saps raw DFs\n",
    "sapsRawDF = pandas.merge( sapsRawDF, sapsDateSelDF, on=\"dateStr\" )\n",
    "\n",
    "prcsdSapsDF = sapsRawDF[ [\"dateStr\", \"hour\",\"sapsLat\", \\\n",
    "                     \"sapsMLT\", \"sapsVel\", \"radId\", \"poesLat\", \"poesMLT\", \"dst_date\", \"dst_index\"] ]\n",
    "\n",
    "prcsdSapsDF[\"time\"] = sapsRawDF[\"date\"].map(lambda x: x.strftime('%H%M'))\n",
    "# Save to a new model file\n",
    "prcsdSapsDF.to_csv(\"../data/processedSaps-new.txt\", sep=' ', index=False)\n",
    "prcsdSapsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # dates = pandas.DatetimeIndex(sapsRawDF.date)\n",
    "# # # get data from only mid-lat radars\n",
    "# sapsRawDF = sapsRawDF[ sapsRawDF[\"radId\"].isin(midlatRadIds) ]\n",
    "# # sapsRawDF.reset_index(inplace=True, drop=True)\n",
    "# sapsDateGrp = sapsRawDF.groupby([\"dateStr\"])\n",
    "# numSapsDates = sapsDateGrp[\"dateTimeString\"].count()\n",
    "# # # get a list of SAPS dates where num of \n",
    "# # # observations is greater than 200.\n",
    "# numSapsDates = numSapsDates[ numSapsDates > 200 ]\n",
    "# sapsDatesList = numSapsDates.index.tolist()\n",
    "# # # get only data points from the selected dates\n",
    "# sapsRawDF = sapsRawDF[sapsRawDF[\"dateStr\"].isin(sapsDatesList)].reset_index(drop=True)\n",
    "# # get a df with proper format\n",
    "# prcsdSapsDF = sapsRawDF[ [\"dateStr\", \"hour\",\"sapsLat\", \\\n",
    "#                      \"sapsMLT\", \"sapsVel\", \"radId\", \"poesLat\", \"poesMLT\", \"dst_date\", \"dst_index\"] ]\n",
    "# prcsdSapsDF[\"time\"] = sapsRawDF[\"date\"].map(lambda x: x.strftime('%H%M'))\n",
    "# prcsdSapsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of saps dates---> 311\n"
     ]
    }
   ],
   "source": [
    "# count number of (saps) dates present in the processed DF\n",
    "uniqSapsDates = prcsdSapsDF[\"dateStr\"].unique().tolist()\n",
    "print \"num of saps dates--->\", len(uniqSapsDates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'hour'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-90c9976d1241>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get daywise min Dst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msapsDFHourDstGrps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprcsdSapsDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dateStr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"hour\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mminDstHourwise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msapsDFHourDstGrps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dst_index\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# We'll use the pandas cut function to bin the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# our bins are --> [-10,10], [-25,-10], [-50,-25], [-75,-50], [-125,-75]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m   3972\u001b[0m         return groupby(self, by=by, axis=axis, level=level, as_index=as_index,\n\u001b[1;32m   3973\u001b[0m                        \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqueeze\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3974\u001b[0;31m                        **kwargs)\n\u001b[0m\u001b[1;32m   3975\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0masfreq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36mgroupby\u001b[0;34m(obj, by, **kwds)\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid type: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m                                                     \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                                                     \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m                                                     mutated=self.mutated)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/groupby.pyc\u001b[0m in \u001b[0;36m_get_grouper\u001b[0;34m(obj, key, axis, level, sort, mutated)\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_in_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# df.groupby('name')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m             \u001b[0min_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgpr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0mexclusions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2057\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2062\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2064\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2066\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1387\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3520\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3521\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3522\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2106\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2108\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4160)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4024)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13161)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:13115)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'hour'"
     ]
    }
   ],
   "source": [
    "# get daywise min Dst\n",
    "sapsDFHourDstGrps = prcsdSapsDF.groupby([\"dateStr\", \"hour\"])\n",
    "minDstHourwise = sapsDFHourDstGrps[\"dst_index\"].min()\n",
    "# We'll use the pandas cut function to bin the data\n",
    "# our bins are --> [-10,10], [-25,-10], [-50,-25], [-75,-50], [-125,-75]\n",
    "bins = [-150,-75,-50,-25,-10,10]\n",
    "hourWiseBins = pandas.cut( minDstHourwise, bins=bins )\n",
    "print pandas.value_counts(hourWiseBins)\n",
    "print pandas.value_counts( allDataHourWiseBins )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set seaborn color\n",
    "seaborn.set_style(\"whitegrid\")\n",
    "seaborn.set_context(\"poster\")\n",
    "dstSapsHoursDF = pandas.concat([ \\\n",
    "                     pandas.value_counts( hourWiseBins ), \\\n",
    "                     pandas.value_counts( allDataHourWiseBins )],\\\n",
    "                    axis=1)#.reset_index()\n",
    "dstSapsHoursDF = dstSapsHoursDF.reindex(index = ['(-150, -75]','(-75, -50]',\\\n",
    "                                               '(-50, -25]', '(-25, -10]', '(-10, 10]']).reset_index()\n",
    "dstSapsHoursDF.columns = [ \"dstRange\", \"sapsdays\", \"totaldays\" ]\n",
    "dstSapsHoursDF[\"sapsPercent\"] = dstSapsHoursDF[\"sapsdays\"]*100/dstSapsHoursDF[\"totaldays\"]\n",
    "# colors - dodgerblue, lightseagreen, palevioletred, skyblue, c\n",
    "hoursBar = seaborn.barplot( dstSapsHoursDF[\"dstRange\"], dstSapsHoursDF[\"sapsPercent\"], color=\"c\" )\n",
    "plt.ylim(0, 100)\n",
    "plt.xlabel(\"Dst index bins\")\n",
    "plt.ylabel(\"Percent Occurrence\")\n",
    "for n,p in enumerate(hoursBar.patches):\n",
    "    titStrg = str( dstSapsHoursDF[\"sapsdays\"][n] ) +\\\n",
    "        \" / \" + str( dstSapsHoursDF[\"totaldays\"][n] )\n",
    "    hoursBar.annotate(\n",
    "        s= titStrg,\n",
    "        xy=(p.get_x()+p.get_width()/2.,p.get_height()),\n",
    "        ha='center',va='center',\n",
    "        xytext=(0,10),\n",
    "        textcoords='offset points'\n",
    ")\n",
    "fig = hoursBar.get_figure()\n",
    "fig.savefig(\"../figs/hoursPercent.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instead of bins go for dst vs percent analysis plot\n",
    "dstHourDF = minDstAllDataHourwise.groupby( [\"dst_index\"] ).count().reset_index()[[\"dst_index\", \"dateStr\"]]\n",
    "dstHourDF.columns = [ \"dst_index\", \"count_total\" ]\n",
    "dstHourDF.head()\n",
    "sapsDFHourDstGrps = prcsdSapsDF.groupby([\"dateStr\", \"hour\"])\n",
    "dstHourwise = sapsDFHourDstGrps[\"dst_index\"].min().reset_index()\n",
    "dstHourwise = dstHourwise.drop_duplicates()\n",
    "dstSapsHourwise = dstHourwise.groupby( [\"dst_index\"] ).count().reset_index()[[\"dst_index\", \"dateStr\"]]\n",
    "dstSapsHourwise.columns = [ \"dst_index\", \"count_saps\" ]\n",
    "dstSapsHourwise.head()\n",
    "# Merge the DFs to get percent saps occ\n",
    "dstSapsHourwise = pandas.merge( dstHourDF, dstSapsHourwise, on=[\"dst_index\"], how='inner')\n",
    "dstSapsHourwise[\"percent\"] = dstSapsHourwise[\"count_saps\"] *100./ dstSapsHourwise[\"count_total\"]\n",
    "dstSapsHourwise.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(12, 8))\n",
    "ax1 = f.add_subplot(1,1,1)\n",
    "\n",
    "# seaborn.set_style(\"darkgrid\")\n",
    "# seaborn.set_context(\"paper\")\n",
    "seaMap = ListedColormap(seaborn.color_palette(\"YlOrRd\"))\n",
    "aa = dstSapsHourwise.plot( kind='scatter',\n",
    "              x='dst_index',\n",
    "              y='percent',\n",
    "              c='count_saps', vmin=0, vmax=100,cmap=seaMap, ax=ax1)\n",
    "ax1.set_ylabel(\"Percent\", fontsize=14)\n",
    "ax1.set_xlabel(\"Dst-index\", fontsize=14)\n",
    "ax1.set_title( \"Percent Occ of SAPS\", fontsize=14 )\n",
    "plt.savefig(\"../figs/sapsPercent.pdf\",bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
